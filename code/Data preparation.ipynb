{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Environment/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from nltk import clean_html, SnowballStemmer, PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Author link</th>\n",
       "      <th>Description</th>\n",
       "      <th>Idea</th>\n",
       "      <th>Idea URL</th>\n",
       "      <th>Long</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Submission Date</th>\n",
       "      <th>Rating Date</th>\n",
       "      <th>...</th>\n",
       "      <th>One Year Index Price</th>\n",
       "      <th>Two Year Index Price</th>\n",
       "      <th>Industry</th>\n",
       "      <th>PE</th>\n",
       "      <th>Psales</th>\n",
       "      <th>PFCF</th>\n",
       "      <th>EV</th>\n",
       "      <th>MKT</th>\n",
       "      <th>Country</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coda516</td>\n",
       "      <td>/member/coda516/11034</td>\n",
       "      <td>\\nDescription\\nRule #1 is “Never Lose Money.” ...</td>\n",
       "      <td>1-800-Contacts</td>\n",
       "      <td>https://valueinvestorsclub.com/idea/1-800-Cont...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2006-11-06</td>\n",
       "      <td>2006-11-20</td>\n",
       "      <td>...</td>\n",
       "      <td>1439.70</td>\n",
       "      <td>806.58</td>\n",
       "      <td>Catalog/Specialty Distribution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.083200</td>\n",
       "      <td>191.964398</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.276761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Den1200</td>\n",
       "      <td>/member/Den1200/31058</td>\n",
       "      <td>\\nDescription\\nI recommend the purchase of BRK...</td>\n",
       "      <td>BERKSHIRE HATHAWAY</td>\n",
       "      <td>https://valueinvestorsclub.com/idea/BERKSHIRE_...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2208.73</td>\n",
       "      <td>2208.73</td>\n",
       "      <td>Financial Conglomerates</td>\n",
       "      <td>13.999246</td>\n",
       "      <td>1.632202</td>\n",
       "      <td>20.436016</td>\n",
       "      <td>398776.915475</td>\n",
       "      <td>367130.543924</td>\n",
       "      <td>United States</td>\n",
       "      <td>7.381747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>piggybanker</td>\n",
       "      <td>/member/piggybanker/31371</td>\n",
       "      <td>\\nDescription\\n\\nWe believe that the stock of ...</td>\n",
       "      <td>1-800-FLOWERS.COM</td>\n",
       "      <td>https://valueinvestorsclub.com/idea/1-800-FLOW...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-10-16</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.65</td>\n",
       "      <td>2079.36</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>25.253501</td>\n",
       "      <td>0.452324</td>\n",
       "      <td>117.987542</td>\n",
       "      <td>401.664760</td>\n",
       "      <td>141.107958</td>\n",
       "      <td>United States</td>\n",
       "      <td>9.552421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahnuld</td>\n",
       "      <td>/member/ahnuld/63009</td>\n",
       "      <td>\\nDescription\\nI know this idea was posted les...</td>\n",
       "      <td>QHR CORP</td>\n",
       "      <td>https://valueinvestorsclub.com/idea/QHR_CORP/1...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2208.73</td>\n",
       "      <td>2208.73</td>\n",
       "      <td>Information Technology Services</td>\n",
       "      <td>497.435897</td>\n",
       "      <td>3.232550</td>\n",
       "      <td>19.339538</td>\n",
       "      <td>146.158744</td>\n",
       "      <td>162.485049</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.322161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shoon1022</td>\n",
       "      <td>/member/shoon1022/23813</td>\n",
       "      <td>\\nDescription\\n \\nAt $2.80, FLWS has an enterp...</td>\n",
       "      <td>1-800-FLOWERS.COM</td>\n",
       "      <td>https://valueinvestorsclub.com/idea/1-800-FLOW...</td>\n",
       "      <td>True</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2011-02-20</td>\n",
       "      <td>2011-03-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.33</td>\n",
       "      <td>1539.79</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.280800</td>\n",
       "      <td>75.961198</td>\n",
       "      <td>United States</td>\n",
       "      <td>-0.393029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author                Author link  \\\n",
       "0      coda516      /member/coda516/11034   \n",
       "1      Den1200      /member/Den1200/31058   \n",
       "1  piggybanker  /member/piggybanker/31371   \n",
       "2       ahnuld       /member/ahnuld/63009   \n",
       "2    shoon1022    /member/shoon1022/23813   \n",
       "\n",
       "                                         Description                Idea  \\\n",
       "0  \\nDescription\\nRule #1 is “Never Lose Money.” ...      1-800-Contacts   \n",
       "1  \\nDescription\\nI recommend the purchase of BRK...  BERKSHIRE HATHAWAY   \n",
       "1  \\nDescription\\n\\nWe believe that the stock of ...   1-800-FLOWERS.COM   \n",
       "2  \\nDescription\\nI know this idea was posted les...            QHR CORP   \n",
       "2  \\nDescription\\n \\nAt $2.80, FLWS has an enterp...   1-800-FLOWERS.COM   \n",
       "\n",
       "                                            Idea URL  Long  Performance  \\\n",
       "0  https://valueinvestorsclub.com/idea/1-800-Cont...  True          NaN   \n",
       "1  https://valueinvestorsclub.com/idea/BERKSHIRE_...  True          3.9   \n",
       "1  https://valueinvestorsclub.com/idea/1-800-FLOW...  True          4.3   \n",
       "2  https://valueinvestorsclub.com/idea/QHR_CORP/1...  True          NaN   \n",
       "2  https://valueinvestorsclub.com/idea/1-800-FLOW...  True          3.4   \n",
       "\n",
       "   Quality Submission Date Rating Date    ...    One Year Index Price  \\\n",
       "0      5.7      2006-11-06  2006-11-20    ...                 1439.70   \n",
       "1      2.6      2016-08-23  2016-09-06    ...                 2208.73   \n",
       "1      4.0      2013-10-16  2013-10-30    ...                 1994.65   \n",
       "2      NaN      2016-08-23  2016-09-06    ...                 2208.73   \n",
       "2      3.8      2011-02-20  2011-03-06    ...                 1364.33   \n",
       "\n",
       "  Two Year Index Price                         Industry          PE    Psales  \\\n",
       "0               806.58   Catalog/Specialty Distribution         NaN  0.813072   \n",
       "1              2208.73          Financial Conglomerates   13.999246  1.632202   \n",
       "1              2079.36                  Internet Retail   25.253501  0.452324   \n",
       "2              2208.73  Information Technology Services  497.435897  3.232550   \n",
       "2              1539.79                  Internet Retail         NaN  0.268181   \n",
       "\n",
       "         PFCF             EV            MKT        Country      ROIC  \n",
       "0         NaN     216.083200     191.964398  United States -6.276761  \n",
       "1   20.436016  398776.915475  367130.543924  United States  7.381747  \n",
       "1  117.987542     401.664760     141.107958  United States  9.552421  \n",
       "2   19.339538     146.158744     162.485049         Canada  3.322161  \n",
       "2         NaN     217.280800      75.961198  United States -0.393029  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbase = '../assets/FULL DB VALUES.xlsx'\n",
    "data = pd.read_excel(dbase, sheet='Sheet1')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['Author link']\n",
    "del data['Idea']\n",
    "del data['Idea URL']\n",
    "del data['Two Year Date']\n",
    "del data['Two Year Index Price']\n",
    "del data['Two Year Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Submission Date'] = pd.to_datetime(data['Submission Date'])\n",
    "data['One Year Date'] = pd.to_datetime(data['One Year Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Text cleaning/pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing text and html (Tokenizing words and sentences, clean HTML, clean text, removing stopwords, stemming and lemmatization)\n",
    "__author__ : Triskelion user@Kaggle (Thanks: Abhishek Thakur & Foxtrot user@Kaggle)\n",
    "\"\"\"\n",
    "\n",
    "# Tokenizing (Document to list of sentences. Sentence to list of words.)\n",
    "def tokenize(str):\n",
    "    '''Tokenizes into sentences, then strips punctuation/abbr, converts to lowercase and tokenizes words'''\n",
    "    return     [word_tokenize(\" \".join(re.findall(r'\\w+', t,flags = re.UNICODE | re.LOCALE)).lower()) \n",
    "            for t in sent_tokenize(str.replace(\"'\", \"\"))]\n",
    "\n",
    "#Removing stopwords. Takes list of words, outputs list of words.\n",
    "def remove_stopwords(l_words, lang='english'):\n",
    "    l_stopwords = stopwords.words(lang)\n",
    "    content = [w for w in l_words if w.lower() not in l_stopwords]\n",
    "    return content\n",
    "        \n",
    "#Clean HTML / strip tags TODO: remove page boilerplate (find main content), support email, pdf(?)\n",
    "def html2text(str):\n",
    "    return clean_html(str)\n",
    "        \n",
    "#Stem all words with stemmer of type, return encoded as \"encoding\"\n",
    "def stemming(words_l, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\"):\n",
    "    supported_stemmers = [\"PorterStemmer\",\"SnowballStemmer\",\"LancasterStemmer\",\"WordNetLemmatizer\"]\n",
    "    if type is False or type not in supported_stemmers:\n",
    "        return words_l\n",
    "    else:\n",
    "        l = []\n",
    "        if type == \"PorterStemmer\":\n",
    "            stemmer = PorterStemmer()\n",
    "            for word in words_l:\n",
    "                l.append(stemmer.stem(word).encode(encoding))\n",
    "        if type == \"SnowballStemmer\":\n",
    "            stemmer = SnowballStemmer(lang)\n",
    "            for word in words_l:\n",
    "                l.append(stemmer.stem(word).encode(encoding))\n",
    "        if type == \"LancasterStemmer\":\n",
    "            stemmer = LancasterStemmer()\n",
    "            for word in words_l:\n",
    "                l.append(stemmer.stem(word).encode(encoding))\n",
    "        if type == \"WordNetLemmatizer\": #TODO: context\n",
    "            wnl = WordNetLemmatizer()\n",
    "            for word in words_l:\n",
    "                l.append(wnl.lemmatize(word).encode(encoding))\n",
    "        return l\n",
    "\n",
    "#The preprocess pipeline. Returns as lists of tokens or as string. If stemmer_type = False or not supported then no stemming.        \n",
    "def preprocess_pipeline(str, lang=\"english\", stemmer_type=\"PorterStemmer\", return_as_str=False, \n",
    "                        do_remove_stopwords=False, do_clean_html=False):\n",
    "    l = []\n",
    "    words = []\n",
    "    if do_clean_html:\n",
    "        sentences = tokenize(html2text(str))\n",
    "    else:\n",
    "        sentences = tokenize(str)\n",
    "    for sentence in sentences:\n",
    "        if do_remove_stopwords:\n",
    "            words = remove_stopwords(sentence, lang)\n",
    "        else:\n",
    "            words = sentence\n",
    "        words = stemming(words, stemmer_type)\n",
    "        if return_as_str:\n",
    "            l.append(\" \".join(words))\n",
    "        else:\n",
    "            l.append(words)\n",
    "    if return_as_str:\n",
    "        return \" \".join(l)\n",
    "    else:\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Description'] = data['Description'].map(lambda x: x[12:].rstrip())\n",
    "data['WordNet Desc'] = data['Description'].apply(lambda x: preprocess_pipeline(x, \n",
    "                                                                               stemmer_type='WordNetLemmatizer',\n",
    "                                                                               do_remove_stopwords=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add relative market returns (Stock performance - index performance)\n",
    "data['Year Return'] = (data['One Year Price']/data['Rating Price']) - 1\n",
    "data['Year Index Return'] = (data['One Year Index Price']/data['Rating Index Price']) - 1\n",
    "data['Outperformance'] = data['Year Return'] - data['Year Index Return']\n",
    "\n",
    "#add length of write-up\n",
    "data['Desc length'] = data['Description'].map(lambda x: len(x))\n",
    "\n",
    "#add logged valuation metrics\n",
    "def log_data(Series):\n",
    "    data['log'+Series] = data[Series].map(lambda x: np.log(x))\n",
    "    \n",
    "log_data('PE')\n",
    "log_data('Psales')\n",
    "log_data('PFCF')\n",
    "log_data('MKT')\n",
    "log_data('EV')\n",
    "log_data('ROIC')\n",
    "\n",
    "#remove non-priced securities\n",
    "data = data[data['Outperformance'].notnull()]\n",
    "data.fillna(0,inplace=True) ##LOOK FOR BEST WAY TO FILL MISSING DATA!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add market cap categories\n",
    "bins = [0,800,8000,data['MKT'].max()]\n",
    "names = ['Small Cap','Medium Cap','Large Cap']\n",
    "data['MKT_category'] = pd.cut(data['MKT'], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sentiment feature\n",
    "from textblob import TextBlob\n",
    "data['Sentiment_polarity'] = data['Description'].map(lambda x: TextBlob(x).sentiment.polarity)\n",
    "data['Sentiment_subjectivity'] = data['Description'].map(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create target classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add market return classifier\n",
    "#0 if underperformed market, 1 if outperformed market\n",
    "def market_binary(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    elif x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "data['Outperformed'] = data['Outperformance'].apply(market_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_excel('../assets/Preprocessed Data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
